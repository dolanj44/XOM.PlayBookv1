[
  {
    "category": "Continuous Integration",
    "question": "Source code management  (SCM) use",
    "option1": "No SCM",
    "option2": "SCM for application code",
    "option3": "SCM for application code and configuration",
    "option4": "SCM for application code, configuration and test source code",
    "option5": "SCM for application code, configuration, test source code and builds and containers"
  },
  {
    "category": "Continuous Integration",
    "question": "Source-code branching",
    "option1": "Never considered branching",
    "option2": "Multiple repositories (copies of source code) used instead of branching",
    "option3": "Centralized workflow (single point of entry for all changes)",
    "option4": "Feature branch workflow (dedicated branch for each feature versus using a centralized single location)",
    "option5": "Gitflow workflow (structured branching policy that accounts for features, hotfixes, and releases)"
  },
  {
    "category": "Continuous Integration",
    "question": "CI prerequisites",
    "option1": "Not ready for CI",
    "option2": "Regular developer check- in to development branch",
    "option3": "Comprehensive automated test harness exists",
    "option4": "Developer environment (local) has access to refreshable test data, application build scripts, standardized environment (app and database)",
    "option5": "Automated build scripts and short test process exist AND developer runs for each check- in"
  },
  {
    "category": "Continuous Integration",
    "question": "CI tool use",
    "option1": "No CI tool",
    "option2": "CI tool with manual build controls",
    "option3": "CI tool with scheduled automated builds\n(tool does not have the knowledge of change in source code branch)",
    "option4": "CI tool with automated change detection and automated deployment from development branch ONLY to development environment",
    "option5": "CI tool with automated change detection and automated deployment from all branches to all environments"
  },
  {
    "category": "Continuous Integration",
    "question": "Automation controlled by CI tool",
    "option1": "Only build automation to development",
    "option2": "Build automation to all of the environments (test, QA, and others)",
    "option3": "Unit test for all layers of the application",
    "option4": "plus security tests",
    "option5": "plus performance tests"
  },
  {
    "category": "Continuous Integration",
    "question": "Integration of developer code",
    "option1": "No check-in, integrate until the whole capability (e.g., module or feature) is complete",
    "option2": "Integrate daily (no unit test runs before commit)",
    "option3": "Integrate as methods (smallest executable code) are complete (no unit test runs before commit)",
    "option4": "Integrate daily after running all unit tests, if unit tests pass; otherwise, STOP",
    "option5": "Integrate as methods are complete after running all unit tests, if unit tests pass; otherwise, STOP"
  },
  {
    "category": "Continuous Integration",
    "question": "Alerts/ notifications and actions during CI",
    "option1": "No ACTION is taken for results of CI activities",
    "option2": "If the build breaks due to a check-in, stop the build process prevent other check- ins to the broken code",
    "option3": "When build does not break with check-in, but unit test fails, but other developers can continue to check their code",
    "option4": "When there is an action, have mechanisms in place to communicate to a configurable set of team members",
    "option5": "Automatically stop the build process until all automated tests pass and there are no build errors"
  },
  {
    "category": "Automated Testing",
    "question": "Automated testing",
    "option1": "No automated tests",
    "option2": "Unit tests"
  },
  {
    "category": "Automated Testing",
    "question": "Actions for automated test results",
    "option1": "No action taken",
    "option2": "Actions are documented and it is left up to developers to fix the problems",
    "option3": "Actions are taken for each sprint",
    "option4": "Problems are reviewed by development team and actions planned into the sprint plans",
    "option5": "When any automated test fails, team stops to triage the problem"
  },
  {
    "category": "Automated Testing",
    "question": "Unit tests",
    "option1": "No unit tests",
    "option2": "Few simple tests",
    "option3": "Design for testability",
    "option4": "Test-driven development for both UIs and APIs",
    "option5": "Code coverage"
  },
  {
    "category": "Automated Testing",
    "question": "Unit test coverage",
    "option1": "No unit test coverage tool used",
    "option2": "Coverage <25%",
    "option3": "Coverage >25% to <50%",
    "option4": "Coverage >50% to <75%",
    "option5": "Coverage >75%"
  },
  {
    "category": "Automated Testing",
    "question": "Unit test frequency",
    "option1": "No unit test",
    "option2": "Developers run their own tests in ad hoc fashion",
    "option3": "Developers run the entire harness at commit",
    "option4": "CI tool runs the harness for development environment and builds for the entire build",
    "option5": "CI tool runs the harness for every build on every environment"
  },
  {
    "category": "Automated Testing",
    "question": "Scenario (functional or story) test coverage",
    "option1": "No automated scenario test",
    "option2": "User story coverage <25%",
    "option3": "User story coverage >25% to <50%",
    "option4": "User story coverage >50% to\n<75%",
    "option5": "User story coverage >75%"
  },
  {
    "category": "Automated Testing",
    "question": "Performance tests",
    "option1": "No performance test",
    "option2": "Performance test selected functionality\n(smoke tests)",
    "option3": "Performance test everything",
    "option4": "Performance test with SLAs (transaction SLA, page load SLA)",
    "option5": "Performance measurement and tests in production"
  },
  {
    "category": "Automated Testing",
    "question": "Performance test frequency",
    "option1": "No performance test",
    "option2": "Ad hoc",
    "option3": "For every release",
    "option4": "For every sprint",
    "option5": "Continuously"
  },
  {
    "category": "Automated Testing",
    "question": "Performance test types",
    "option1": "No performance tests",
    "option2": "Performance test",
    "option3": "#ERROR!",
    "option4": "#ERROR!",
    "option5": "#ERROR!"
  },
  {
    "category": "Automated Testing",
    "question": "Security test types",
    "option1": "No security tests",
    "option2": "Vulnerability scanning",
    "option3": "#ERROR!",
    "option4": "#ERROR!",
    "option5": "#ERROR!"
  },
  {
    "category": "Automated Testing",
    "question": "Vulnerability scanning frequency",
    "option1": "No vulnerability scanning",
    "option2": "Performed by another team after the release is ready",
    "option3": "For every release by the development team",
    "option4": "For every sprint, by the development team",
    "option5": "For every checked-in file, by the CI tool"
  },
  {
    "category": "Automated Testing",
    "question": "Automated code quality review frequency",
    "option1": "No automated code quality scanning",
    "option2": "Performed by technical lead at random code reviews",
    "option3": "For every release by the development team",
    "option4": "For every sprint, by the development team",
    "option5": "For every checked in file, by the CI tool"
  },
  {
    "category": "Automated Testing",
    "question": "Static analysis",
    "option1": "No static analysis tool used",
    "option2": "Heavy-duty static analysis tool (e.g., IBM AppScan) used at project level",
    "option3": "Developers use static analysis tool (suitable for the technical stack) for each file commit",
    "option4": "CI initiates the tool developers use at every code deployment",
    "option5": "CI initiates the developer code at every deployment for the code base and the project tool for defined frequency (e.g., every sprint, release)"
  },
  {
    "category": "Automated Testing",
    "question": "Penetration Testing Frequency",
    "option1": "No penetration scanning",
    "option2": "Performed by another team at the time of a security accreditation",
    "option3": "Performed by another team for every release",
    "option4": "Performed by another team for every sprint",
    "option5": "For every checked in file, by the CI tool"
  },
  {
    "category": "IaC",
    "question": "Automated infrastructure provisioning",
    "option1": "No automated infrastructure provisioning",
    "option2": "Data center set up, physical servers virtualized, and allocated to applications manually",
    "option3": "IaaS is used; on demand infrastructure resources creation when manually requested",
    "option4": "Infrastructure provisioning automated by APIs, but not tied to application scalability",
    "option5": "Infrastructure is provisioned dynamically as the use increases and decreases"
  },
  {
    "category": "IaC",
    "question": "Containerization use",
    "option1": "No containerization",
    "option2": "Containerized monolithic application deployment",
    "option3": "Containerized modules and independent provisioning of the containerized modules",
    "option4": "Containerized microservices and auto scale of microservices on existing ready–to-use infrastructure",
    "option5": "Containerized microservices and integrated auto scale of containers and underlying infrastructure"
  },
  {
    "category": "Continuous Delivery",
    "question": "Automated acceptance tests",
    "option1": "No automated acceptance test suite There is human interaction and gate reviews",
    "option2": "100% coverage with automated acceptance tests used as the “definition of done” for the development team",
    "option3": "Product owner uses the results, but performs manual tests as well before go-live decision",
    "option4": "Product owner relies on automated acceptance tests completely to go live with the build"
  },
  {
    "category": "Continuous Delivery",
    "question": "Contract constraints",
    "option1": "Contract does not allow results of automated tests to be used for delivery",
    "option2": "Builds tested and delivered to development and test environments without manual intervention (fully automated)",
    "option3": "Builds to QA and UAT environments pass through manual testing gate",
    "option4": "Builds delivered to QA and UAT environments without any manual intervention (i.e., data, configuration, networking)"
  },
  {
    "category": "Continuous Delivery",
    "question": "Deployment pipeline",
    "option1": "No automated deployment pipeline",
    "option2": "Deployment pipeline allows CI and deployment to QA and test environments",
    "option3": "Deployment pipeline is configurable to enable full automation from development to production deployment, but cannot be used due to contractual gates",
    "option4": "Fully automated deployment pipeline exists\nIt’s possible to insert a manual approval step, which is used with or without a manual check for production deployment"
  },
  {
    "category": "Continuous Deployment",
    "question": "Deployment to production",
    "option1": "System is taken\noffline\nAll conducted manually using standard operating procedures and step- by-step installation guide",
    "option2": "System is taken offline\nStep-by-step installation, but ALL steps include automated configurations",
    "option3": "System is taken offline\nOne-click deployment is performed and tested before go live",
    "option4": "Zero downtime release System is upgraded with the\nbuild without taking the system down"
  },
  {
    "category": "Continuous Deployment",
    "question": "Deployment capabilities",
    "option1": "No automated deployment",
    "option2": "Canary releasing; build deployed to canary environment first  After testing the canary in production build, the system is taken down and the upgrade is performed",
    "option3": "First deploy to canary and then upgrade servers one at a time until the deployment is complete\nNo downtime",
    "option4": "Blue/green deployment\nNo downtime (two identical versions of production: blue and green; one is upgraded and replaced with the other at the DNS level)"
  },
  {
    "category": "Continuous Monitoring",
    "question": "Monitoring solution",
    "option1": "Limited used of monitoring tools by the operations team",
    "option2": "Monitoring types:\n• Application performance monitoring\n• Log monitoring and analysis\n• Security monitoring",
    "option3": "Three monitoring types:\n• Application performance monitoring\n• Log monitoring and analysis\n• Security monitoring",
    "option4": "All of these monitoring types:\n• Application performance monitoring\n• Log monitoring and analysis\n• Security monitoring"
  },
  {
    "category": "Continuous Monitoring",
    "question": "Application performance monitoring",
    "option1": "Manual application performance monitoring using OS tools",
    "option2": "Easy access to real-time statistics on application performance in production",
    "option3": "Ability to isolate issues in production down to the individual servers/VM/ containers and processes",
    "option4": "Ability to view the entire stack of any issue identified, from initial request down to the database"
  },
  {
    "category": "Continuous Monitoring",
    "question": "Log monitoring",
    "option1": "Log monitoring using OS tools",
    "option2": "All logs (i.e., application, security, web access) easily accessible for review",
    "option3": "All logs consolidated and put in a central location",
    "option4": "All logs are indexed and quickly searchable"
  },
  {
    "category": "Continuous Monitoring",
    "question": "Security monitoring",
    "option1": "Security monitoring using basic OS and network tools",
    "option2": "Simple threat identification,\nsuch as various DoS attacks",
    "option3": "Advanced network monitoring to actively find vulnerabilities or active attacks",
    "option4": "Monitor payloads that are hitting the system for identifying possible attacks"
  },
  {
    "category": "Continuous Monitoring",
    "question": "Alerting solution",
    "option1": "Responsible parties are alerted by team monitoring logs, application, and security",
    "option2": "Alerts provide detailed information about the nature of monitoring trigger",
    "option3": "Alerting solution provides historic list of previous events, including event details",
    "option4": "Alerting thresholds are\nmodifiable"
  }
]